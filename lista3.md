# Lista 3

## MDP

### CapÃ­tulo 16

#### **2.** Chris avalia 4 carros usados antes de comprar aquele que tem a maior utilidade esperada. Pat avalia 10 carros e tambÃ©m deseja comprar o de maior utilidade esperada. Considerando condiÃ§Ãµes de anÃ¡lise iguais para Chris e Pat, quem tem mais chances de comprar o melhor carro? Quem tem mais chances de se arrepender da qualidade do carro? VocÃª conseguiria quantificar essas chances em termos do desvio padrÃ£o da qualidade esperada?

Suponha que existam **n** carros e dois estados diferentes, escolher o melhor carro ou nÃ£o. A utilidade esperada para escolher o melhor carro dentre **n** carros Ã©

![EU(S_{i}) = \sum_{i}^{n} p \cdot  U(s_{i})](https://latex.codecogs.com/gif.latex?EU(S_{i})&space;=&space;\sum_{i}^{n}&space;p&space;\cdot&space;U(s_{i}))

![EU(S_{i}) = \sum_{i}^{n} p \cdot  1](https://latex.codecogs.com/gif.latex?EU(S_{i})&space;=&space;\sum_{i}^{n}&space;p&space;\cdot&space;1)

![EU(S_{i}) = n \cdot p](https://latex.codecogs.com/gif.latex?EU(S_{i})&space;=&space;n&space;\cdot&space;p)

Chris tem ``U(s) = 4p`` e Pat tem ``U(s) = 10p``.


#### **3.** Em 1713, Nicolas Bernoulli formulou um puzzle, agora conhecido como "o paradoxo de SÃ£o Petersburgo", que funciona da seguinte maneira.  VocÃª tem a oportunidade de jogar um jogo no qual uma moeda justa Ã© lanÃ§ada repetidamente atÃ© que o resultado seja "cara". A primeira vez que aparecer "cara" no n-Ã©simo lanÃ§amento, vocÃª ganha 2^n reais

#### a) Mostre que o valor monetÃ¡rio esperado desse jogo Ã© infinito
```
EMV(L) = somatÃ³ria de n atÃ© infinito, da probabilidade de cara aparecer na jogada n vezes a utilidade esperada.

EMV(L) = SOMA(1 atÃ© infinito, 2^-n * 2^n)
EMV(L) = SOMA(1 atÃ© infinito, 1)
EMV(L) = infinito
```

#### b) Quanto vocÃª pagaria para jogar esse jogo?
```
n = 1, U = 2, P = 0.5
n = 2, U = 4, P = 0.25
n = 3, U = 8, P = 0.125
```

Em torno de 4 reais, pois para ganhar mais que isso, a probabilidade jÃ¡ Ã© muito baixa.

#### c) Daniel Bernoulli, primo de Nicolas, resolveu o aparente paradoxo em 1738 sugerindo que a utilidade monetÃ¡ria fosse medida usando uma escala logarÃ­tmica (ou seja, *U(S<sub>n</sub>) = a * log2 n + b*, em que *S<sub>n</sub>* Ã© o estado com *R$n*). Qual Ã© a utilidade esperada para o jogo sob essa suposiÃ§Ã£o.

Assumindo o patrimonio inicil de (k - c), onde c Ã© o preÃ§o do jogo:

```
U(L) = somatoria(1 atÃ© infinito, 2^-n * a * log2(k - c + 2^n) + b);
```

Assumindo k - c = 0 para simplificar:
```
U(L) =  somatoria(1 atÃ© infinito, 2^-n * (a * log2(2^n) + b);
U(L) =  somatoria(1 atÃ© infinito, 2^-n * a * n + b;
U(L) = 2 * a + b;
```

#### d) Qual seria a quantidade mÃ¡xima que alguÃ©m pagaria para jogar o jogo, assumindo que essa pessoa jÃ¡ possui *R$k*?

```
a * log2c + b = 2 * a + b;
c = 4;
```

### **6.** Prove que as preferÃªncias ğµ â‰» ğ´ e ğ¶ â‰» ğ· no paradoxo de Allais (pÃ¡gina 620) viola o axioma de substituiÃ§Ã£o.



### **7.** Considere o paradoxo de Allais descrito na pÃ¡gina 620: um agente que prefere B em relaÃ§Ã£o a A, e C em relaÃ§Ã£o a D (assumindo o maior valor monetÃ¡rio esperado (EMV)) nÃ£o estÃ¡ agindo racionalmente, de acordo com a teoria da utilidade. VocÃª acha que isso seria um problema para o agente, um problema para a teoria, ou nÃ£o hÃ¡ problema algum? Justifique.



### **8.** Bilhetes para uma loteria custam ğ‘…$1. Existem dois possÃ­veis prÃªmios: ğ‘…$10,00 com probabilidade 1/50 e ğ‘…$1.000.000,00 com probabilidade 1/2.000.000. Qual Ã© o valor monetÃ¡rio esperado para o bilhete da loteria? Por qual valor (se houver) seria razoÃ¡vel comprar um bilhete? Seja preciso - mostre uma equaÃ§Ã£o envolvendo utilidades. VocÃª pode assumir que seu saldo atual Ã© ğ‘…$ğ‘˜ e que ğ‘ˆ(ğ‘†ğ‘˜) = 0. VocÃª tambÃ©m pode assumir que ğ‘ˆ(ğ‘†ğ‘˜+10) = 10 Ã— ğ‘ˆ(ğ‘†ğ‘˜+1), mas vocÃª nÃ£o pode assumir nada sobre ğ‘ˆ(ğ‘†ğ‘˜+1.000.000). Estudos sociolÃ³gicos mostram que pessoas com renda baixa compram um nÃºmero de bilhetes de forma nÃ£o proporcional. VocÃª acha que isto Ã© resultado de uma decisÃ£o ruim ou de um uso de uma funÃ§Ã£o utilidade diferente?

```
p(10) = 1/50;
p(1.000.000) = 1/2.000.000;

EMV(L) = somatoria(1 atÃ© n, probabilidade de n * utilidade esperada);
EMV(L) = 1/50 * 10 + 1/2.000.000 * 1.000.000 = 0,70;
```

```

```

### CapÃ­tulo 17

#### **1.** Para o mundo 4 Ã— 3 mostrado na Figura 17.1, calcule quais quadrados podem ser alcanÃ§ados a partir de (1, 1),  pela sequÃªncia de aÃ§Ãµes [cima, cima, direita, direita, direita] e com quais probabilidades.

Deve-se somar a probabilidade de ir para aquele quadrante a cada passo do tempo. Por exemplo:

* No primeiro passo, existe probabilidade 0,8 de ir para (1,2), 0,1 para ficar em (1,1) e 0,1 de ir para (2,1);
* Para continuar em (1, 1) existe probabilidade 0,1^2, caso ainda esteja em (1, 1), e probabilidade 0,1^2 caso esteja em (2,1), somando um total de 0,02;

(ver solucionÃ¡rio)

#### **3.** Suponha que nÃ³s definimos a utilidade de uma sequÃªncia de estados para ser a mÃ¡xima recompensa obtida em qualquer estado da sequÃªncia. Mostre que esta funÃ§Ã£o utilidade nÃ£o resulta em preferÃªncias estacionÃ¡rias entre sequÃªncias de estado. Seria possÃ­vel definir uma funÃ§Ã£o utilidade em estados tal que a decisÃ£o por mÃ¡xima utilidade esperada (MEU) resulta no comportamento Ã³timo do agente?



#### **5.** Para o ambiente mostrado na Figura 17.1, encontre os valores limites *(threshold)* para *R(s)* tal que a polÃ­tica Ã³tima muda quando o valor limite Ã© cruzado. VocÃª irÃ¡ precisar calcular a polÃ­tica Ã³tima e seu valor fixo *R(s)*. Dica: Prove que o valor de qualquer polÃ­tica fixa varia linearmente com *R(s)*.

#### **8.** Considere o mundo 3 Ã— 3 mostrado na Figura 17.14(a). O modelo de transiÃ§Ã£o Ã© mesmo que aquele do mundo 4 Ã— 3 na Figura 17.1: 80% do tempo o agente vai na direÃ§Ã£o que ele seleciona; no restante do tempo ele vai em direÃ§Ã£o ortogonal Ã quela pretendida. Implemente o algoritmo de valor-iteraÃ§Ã£o para este mundo para cada um dos valores de *r* abaixo. Use recompensas com desconto com um fator de g = 0.99. Mostre a polÃ­tica obtida em cada caso. Explique intuitivamente por que o valor de *r* leva a cada polÃ­tica.

##### a) *r* = 100

##### b) *r* = -3

##### c) *r* = 0

##### d) *r* = +3

#### **10.** Considere um MDP com trÃªs estados, (1, 2, 3), com recompensas âˆ’1, âˆ’2, 0, respectivamente. O estado 3 Ã© um estado terminal. Nos estados 1 e 2, hÃ¡ duas aÃ§Ãµes possÃ­veis: *a* e *b*. O modelo de transiÃ§Ã£o Ã© como segue:<br /><br />â€¢ No estado 1, a aÃ§Ã£o *a* move o agente para o estado 2 com probabilidade 0.8 ou faz com que o agente permaneÃ§a no mesmo estado com probabilidade 0.2.<br />â€¢ No estado 2, a aÃ§Ã£o *a* move o agente para o estado 1 com probabilidade 0.8 ou faz com que o agente permaneÃ§a no mesmo estado com probabilidade 0.2.<br />â€¢ No estado 1 ou estado 2, a aÃ§Ã£o *b* move o agente para o estado 3 com probabilidade 0.1 ou faz com que o agente permaneÃ§a no mesmo estado com probabilidade 0.9.<br /><br />Com base nisso, responda as seguintes questÃµes:

##### a) O que pode ser determinado qualitativamente sobre a polÃ­tica Ã³tima nos estados 1 e 2?

##### b) Aplique o algortimo de polÃ­tica-iteraÃ§Ã£o, mostrando cada passo, para determinar a polÃ­tica Ã³tima e os valores dos estados 1 e 2. Assuma que a polÃ­tica inicial tem aÃ§Ã£o *b* em ambos os estados

##### c) O que acontece com o algoritmo de polÃ­tica-iteraÃ§Ã£o se a polÃ­tica inicial tem aÃ§Ã£o *a* em ambos os estados? Aplicar desconto ajuda? A polÃ­tica Ã³tima depende do fator de desconto?